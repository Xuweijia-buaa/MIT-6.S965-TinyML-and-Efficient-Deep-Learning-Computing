# MIT-6.S965-TinyML-and-Efficient-Deep-Learning-Computing


Course Outline
• Basics of Deep Neural Networks (DNNs)
• Efficient Inference of Neural Networks
• Pruning, Quantization, Neural Architecture Search, Knowledge Distillation
• Efficient Training of Neural Networks
• Distributed Training, Gradient Compression, On-Device Learning, Transfer Learning
• System Support for Efficient Deep Learning Computing
• Application-Specific Optimization of Deep Learning Computing
• Point Cloud Recognition, Video Understanding, GANs, Transformers
• Quantum Machine Learning


Labs
• Lab 0 - Getting Started (Due Sep 15, not counted to the final grades)
• Lab 1 - Pruning (Due Oct 4)
• Lab 2 - Quantization (Due Oct 18)
• Lab 3 - Neural Architecture Search (Due Nov 1)
• Lab 4 - Deploy TinyML Models on Microcontrollers (Due Nov 17)
